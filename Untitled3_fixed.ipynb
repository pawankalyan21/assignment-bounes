{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# Define context and question\n",
    "context = \"Charles Babbage is considered the father of the computer. He invented the first mechanical computer.\"\n",
    "question = \"Who is considered the father of the computer?\"\n",
    "\n",
    "# Get prediction\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(result)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376,
     "referenced_widgets": [
      "843810e3effd4e139b17bfefaec70944",
      "9147fb4a6e9e4bbfa8c453ae92ece168",
      "c2555d61594241ffa2d16124441574e2",
      "828b0bd3831b410f9e81b73fb4a39fa4",
      "be279a7cca6e4a11abd7ceae271892c8",
      "1145d4ace3a144139fce869ef0e48821",
      "6a74f52ca6d44f79af5423ddbf71cd93",
      "39a964f4ced345fa915b39d0b46340be",
      "3072d1b028df49bba9ee520028903386",
      "1cdb9d8e381a42ddaf3c6f6d0d7f77a0",
      "2e3c22497cee44219e1b5721b26c0aad",
      "4af9e608802f40f6b1078ac21c4e69cb",
      "22ef01f45fcd450f83ccffba2472afc3",
      "31c54ba97a76450096e274660b1a795c",
      "62c4406e66d04522a941e42fe01418ae",
      "797f4e649f57469eb49a898e7fffeee0",
      "6c075bfc98be4f469faf6f4a059f6eb4",
      "baeaa29370744adcab3f0d70fec81518",
      "d2c3b2e2d8e5431a82210448609b4ae4",
      "292984d1263441dbaae6debe8167eaea",
      "6dbb28a6f16e463ebf23b7dac9a820af",
      "0a5b02d2ff884b119ecd02885a8f6593",
      "e33024ecc68845edadb65afa6dc89e57",
      "f8e0b24119f3495b9da76e430c37dd5b",
      "1801f3f52f0a4ce4be1f572752aa19f2",
      "de661f493940454e9f410f7cbc9da127",
      "e0987f9dab1f491ab873b44957ae83b3",
      "80b809cb686e46439471e6c1466b2439",
      "7164818699f3432da7f8fa1bf9f4825a",
      "d3b732c33b584d62b10d9f065c87a6c7",
      "908f56bfd96f4f4bbaf970ca87738425",
      "3c0026408c6c479e84819d15c2c31979",
      "87a1bad1fa1b47b1a780d143f80c68da",
      "ad646db2ce0c4040a19397391bff5cd9",
      "afc76802e8ba455fb9a8c1f4002e24a4",
      "cee1b3300e08450d969f5c4646dd7efb",
      "3d1d966eb9e74d31ac48a08ab31e1f34",
      "7f360b962bf44cb7a913e7462039e71e",
      "740f2f7569ca4fae9f67ea5a52a3ea16",
      "99158c682efa424b87f52c627cee1f00",
      "076f422d74db4cd58e3e6521b56b347d",
      "84498feb6b244b27a87ffadc44b3e4c8",
      "5e613b38dce5487f8a8334cabebbd0ff",
      "9c028942378443898798d2f7ba349dc7",
      "b7a618cd498c428da10da3097f2a5bd4",
      "ad8c6a9966fa4d12867736a37071ec00",
      "5e8b350a58284a3f81ad2c6eea4a930a",
      "9103a2b175244e7aa5388585e5fb168f",
      "26d38af6eff74ff3b17f08fcb4112903",
      "e9e4663980b64be3ae0879847048afff",
      "35881633116740898ee77ab620a92321",
      "ac7c4c178b9e4d8aa73f454067730647",
      "42ee61c6771b495fb6a92c1d09f6a491",
      "159893a15796464a8937c372f30f3b32",
      "5d2d87f801da47b9ad443856c66d5bd3"
     ]
    },
    "id": "yiVjwecQXdyJ",
    "outputId": "96bef326-15a7-42ff-8433-7879371f8738"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "843810e3effd4e139b17bfefaec70944"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4af9e608802f40f6b1078ac21c4e69cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e33024ecc68845edadb65afa6dc89e57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad646db2ce0c4040a19397391bff5cd9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7a618cd498c428da10da3097f2a5bd4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'score': 0.9978974461555481, 'start': 0, 'end': 15, 'answer': 'Charles Babbage'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use a specific QA model\n",
    "qa_pipeline_custom = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "context = \"Charles Babbage is considered the father of the computer. He invented the first mechanical computer.\"\n",
    "question = \"Who is considered the father of the computer?\"\n",
    "\n",
    "# Get prediction\n",
    "result_custom = qa_pipeline_custom(question=question, context=context)\n",
    "\n",
    "print(result_custom)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265,
     "referenced_widgets": [
      "d8f77d4b20d84e78a82a6c04b98b8a65",
      "7dc8d472e31344fb93b3ff8815543a14",
      "ee843f8727604f5aaf69d2bf581e4825",
      "e8c8d1d107ed4d7486713da499b1c1f3",
      "84126586335a43f99afda1f9112f4d7f",
      "9a124835499c48c88a3f8af5a81e6626",
      "fd7ebd24439b4205a9bd2ba01cce921f",
      "3bfb6b3deccb4edb8ae8e06a23172f3b",
      "9f5a394cf27741f28d5aa8e7869c5f73",
      "cf2a91194e7f43a896f432b76cff556e",
      "931f76c0d9214453b39e575fae4a2a91",
      "9a879f25ead44e6198dfe65bb0b952b0",
      "3c63920d94c5464588f0b30610982d8a",
      "19bdaa58cbef4708b7b20b53bbee938c",
      "38ad207ce5ff4f7a8be9040897685483",
      "cd3b8890c4154775b2c153ac1eaf2da8",
      "cd92fb07a269447e8d12f19e72ba2a22",
      "9512ac6dc83a4ed49749d3b4669cd001",
      "47f800915d4b43b6bce027dddcf4c386",
      "ce1b1abc245646f9ba3a79f47a57be20",
      "a8fb6989266346a983a8b274807f29f2",
      "e2717dfb84ec489b8ad243cb4b965abe",
      "5284bbb244404981866e99f05c523172",
      "1fee3621df294e26a3d16c64e28322d6",
      "4b3d2c1c6feb47069860e12fd27887aa",
      "beaa5b2202dc443eb125d2c86d035be3",
      "37dda6b9d0854fcc8fe0cf5cfac6f787",
      "6647b1c2d41f4e5b8525ad9ca8e72c44",
      "0f9370a2e37c4bb9a2d4d688762dbb33",
      "81ba751b2f4d46eea076ab70319680bf",
      "8ab2b594f0074a13a51fbd59e2089802",
      "865ef9d00a9f466881fb05fa0815ea72",
      "d39b5fee4cb34f8db9d09de3d6955aa1",
      "8f300eeb5dfc4b31b6ab621274baabc7",
      "5920ee04a7b14cc8b14fb876d0223d82",
      "d57c1e75028b4fd285cbdaa9241deb9a",
      "dd63cd746161411b9c113252ae0e232c",
      "070621fca4094478be05a5d3e823f441",
      "60acf79662884d28b4ad131b4f15767b",
      "4510f35869b64d2a82df0d21db078ddc",
      "f3d5efada65845dd9944943161705aba",
      "63981ca51a8a48e181c5ac81a5eedda4",
      "84197312e8a545e8a2a2e2b7be6fadbf",
      "09818e443d1a429b8ad55ad9ffd7b039",
      "69984c3f2ede464f926a359c2fd72b0f",
      "0a68c0f8131b4c058171016a5a47a4b9",
      "60021eaedf18410baa92ce96ef9756cf",
      "3cbad38bdcf64640b377f6c416253477",
      "095978aafe3c48728489a5f094d0cc51",
      "3eeb9e11c02a48e58b631b18fafdba24",
      "16af681f93724e9c906950bedca73d6f",
      "375bb63d792c4488b359b04172b3d4e8",
      "7c54bc40e9174409bc30dd7964101b2c",
      "45f0ded4f40c48129c5c7083664413b1",
      "c91d43cd9a1e48ceb07550a8a0368a62",
      "c65756f07e904a08b86e0ae1868cd72c",
      "25a611dd914c4f21b22c3fb80b7ce7a1",
      "dd6110e8261d4c59acd0d651d2fbf0a4",
      "a4c0b33427934839bf3a37e4d9fb621e",
      "c75b5c59aaac40939b69e5de0e9e2cc2",
      "311e154c739d45eaafe1f72bd6f658b1",
      "10e44162521b4de3884f9316de949fcd",
      "1381f02dc96d448d8e952c71e4d6f298",
      "9ac1488f05704cec9d8ddd49d8c46cc3",
      "baf5f4fb69c84eaf9b63b5de6415ae5d",
      "87364e1e479f4ae5aa478985b22088c9"
     ]
    },
    "id": "euqqwp0gXxcR",
    "outputId": "4ae6ef17-c480-4460-bcd7-67e8f6468cb1"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8f77d4b20d84e78a82a6c04b98b8a65"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a879f25ead44e6198dfe65bb0b952b0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5284bbb244404981866e99f05c523172"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f300eeb5dfc4b31b6ab621274baabc7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69984c3f2ede464f926a359c2fd72b0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c65756f07e904a08b86e0ae1868cd72c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'score': 0.9878972172737122, 'start': 0, 'end': 15, 'answer': 'Charles Babbage'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom context\n",
    "context = \"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976. The company is known for the iPhone and Mac computers.\"\n",
    "\n",
    "# Question 1\n",
    "q1 = \"Who founded Apple Inc.?\"\n",
    "result1 = qa_pipeline_custom(question=q1, context=context)\n",
    "\n",
    "# Question 2\n",
    "q2 = \"What products is Apple known for?\"\n",
    "result2 = qa_pipeline_custom(question=q2, context=context)\n",
    "\n",
    "print(\"Answer 1:\", result1)\n",
    "print(\"Answer 2:\", result2)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKTrGjTOYMfy",
    "outputId": "376c3ecd-09c9-40f6-d1b5-ddeaffe09322"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Answer 1: {'score': 0.9786236882209778, 'start': 26, 'end': 69, 'answer': 'Steve Jobs, Steve Wozniak, and Ronald Wayne'}\n",
      "Answer 2: {'score': 0.7343839406967163, 'start': 108, 'end': 132, 'answer': 'iPhone and Mac computers'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "img_dim = 28 * 28\n",
    "label_dim = 10\n",
    "noise_dim = 100\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "lr = 0.0002\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(10, label_dim)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        x = torch.cat([z, self.label_emb(labels)], dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(10, label_dim)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_dim + label_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        x = torch.cat([img, self.label_emb(labels)], dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize models\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "# Optimizers and loss\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for real_imgs, labels in loader:\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.view(batch_size, -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Real and fake targets\n",
    "        real_targets = torch.ones(batch_size, 1).to(device)\n",
    "        fake_targets = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # ========== Train Discriminator ==========\n",
    "        z = torch.randn(batch_size, noise_dim).to(device)\n",
    "        fake_labels = torch.randint(0, 10, (batch_size,)).to(device)\n",
    "        fake_imgs = G(z, fake_labels)\n",
    "\n",
    "        d_real = D(real_imgs, labels)\n",
    "        d_fake = D(fake_imgs.detach(), fake_labels)\n",
    "\n",
    "        d_loss = criterion(d_real, real_targets) + criterion(d_fake, fake_targets)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ========== Train Generator ==========\n",
    "        z = torch.randn(batch_size, noise_dim).to(device)\n",
    "        gen_labels = torch.randint(0, 10, (batch_size,)).to(device)\n",
    "        gen_imgs = G(z, gen_labels)\n",
    "        d_gen = D(gen_imgs, gen_labels)\n",
    "\n",
    "        g_loss = criterion(d_gen, real_targets)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]  D_loss: {d_loss.item():.4f}  G_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# ========== Generate digits for labels 0-9 ==========\n",
    "def show_generated_digits():\n",
    "    G.eval()\n",
    "    z = torch.randn(10, noise_dim).to(device)\n",
    "    labels = torch.arange(0, 10).to(device)\n",
    "    with torch.no_grad():\n",
    "        gen_imgs = G(z, labels).view(-1, 1, 28, 28)\n",
    "    gen_imgs = gen_imgs.cpu() * 0.5 + 0.5  # Denormalize\n",
    "\n",
    "    grid = torch.cat([img.squeeze(0) for img in gen_imgs], dim=1)\n",
    "    plt.imshow(grid, cmap=\"gray\")\n",
    "    plt.title(\"Generated digits from labels 0 to 9\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_generated_digits()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uC4knOOlY6Dm",
    "outputId": "85cc9bc5-c6b7-4972-d203-2a23878182c6"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.91M/9.91M [00:00<00:00, 15.9MB/s]\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28.9k/28.9k [00:00<00:00, 495kB/s]\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.65M/1.65M [00:00<00:00, 3.87MB/s]\n",
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.54k/4.54k [00:00<00:00, 1.13MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/50]  D_loss: 0.4526  G_loss: 1.5599\n",
      "Epoch [2/50]  D_loss: 0.3589  G_loss: 2.1359\n",
      "Epoch [3/50]  D_loss: 0.6236  G_loss: 3.2615\n",
      "Epoch [4/50]  D_loss: 0.5148  G_loss: 1.6094\n",
      "Epoch [5/50]  D_loss: 1.0118  G_loss: 1.3264\n",
      "Epoch [6/50]  D_loss: 1.0447  G_loss: 1.1838\n",
      "Epoch [7/50]  D_loss: 0.8520  G_loss: 1.1650\n",
      "Epoch [8/50]  D_loss: 1.0715  G_loss: 1.4471\n",
      "Epoch [9/50]  D_loss: 0.9843  G_loss: 1.1510\n",
      "Epoch [10/50]  D_loss: 0.9928  G_loss: 1.0829\n",
      "Epoch [11/50]  D_loss: 1.1546  G_loss: 0.8249\n",
      "Epoch [12/50]  D_loss: 1.0821  G_loss: 0.9916\n",
      "Epoch [13/50]  D_loss: 1.2017  G_loss: 0.8859\n",
      "Epoch [14/50]  D_loss: 0.9203  G_loss: 1.0561\n",
      "Epoch [15/50]  D_loss: 1.3614  G_loss: 0.7970\n",
      "Epoch [16/50]  D_loss: 1.2354  G_loss: 1.0408\n",
      "Epoch [17/50]  D_loss: 1.1397  G_loss: 1.0442\n",
      "Epoch [18/50]  D_loss: 1.4190  G_loss: 1.0421\n",
      "Epoch [19/50]  D_loss: 1.0400  G_loss: 1.0872\n",
      "Epoch [20/50]  D_loss: 1.7758  G_loss: 0.8227\n",
      "Epoch [21/50]  D_loss: 0.8418  G_loss: 1.3840\n",
      "Epoch [22/50]  D_loss: 1.3349  G_loss: 1.0855\n",
      "Epoch [23/50]  D_loss: 1.4626  G_loss: 0.9843\n",
      "Epoch [24/50]  D_loss: 2.2191  G_loss: 0.5774\n",
      "Epoch [25/50]  D_loss: 1.4202  G_loss: 1.1547\n",
      "Epoch [26/50]  D_loss: 1.1073  G_loss: 1.1037\n",
      "Epoch [27/50]  D_loss: 1.1990  G_loss: 1.1031\n",
      "Epoch [28/50]  D_loss: 0.8968  G_loss: 1.3656\n",
      "Epoch [29/50]  D_loss: 1.1809  G_loss: 0.9597\n"
     ]
    }
   ]
  }
 ]
}